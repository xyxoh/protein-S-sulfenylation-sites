import math
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, roc_curve, auc
import torch
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from keras.layers import Dense, Activation, Dropout,BatchNormalization
from tensorflow.python.keras.utils import np_utils
import numpy as np
import random
from keras.layers import LSTM
from sklearn import model_selection
from keras.layers import Dense, Activation, Dropout
# 同步式分布式策略，单机多卡训练
mirrored_strategy = tf.distribute.MirroredStrategy()

# 导入数据
savepath = '/home/stu1/xyx/sulf/sulf_rnn'
model_name = 'dnn_EAAC_delate_10'

data = []
label = []
for line in open("/home/stu1/wjr/others/sss/iLearn-master/encoding/EAAC.txt","r"): #设置文件对象并读取每一行文件
    line=line.strip('\n')
    #print(line)
    label.append(int(line.split('\t')[0]))
    #print(line.split('\t')[0])   
    nums = line.split('\t')[1:] 
    #print(nums)  
    nums = [float(x) for x in nums]
    #print(nums)                           
    data.append(nums)#将每一行文件加入到list中


print(np.shape(data))
#print(data)
print(np.shape(label))

data= np.array(data)
y = np.array(label)
random.seed(42)
x_1 = list(data[y==1])
x_0 = list(data[y==0])
x_new_0 = random.sample(x_0,len(x_1)+400)
y =np.hstack((np.ones(len(x_1)),np.zeros(len(x_1)+400)))
#print(y)
print(len(x_1))
print(len(x_0))
print(len(x_new_0))
x = np.vstack((np.array(x_1),np.array(x_new_0)))
print('转换后个数',x.shape)
long = x.shape[1]
x = x.reshape(x.shape[0],x.shape[1])

y = y.reshape(len(y),1)
x_train, x_test, y_train, y_test = model_selection.train_test_split( x, y, test_size=0.1, random_state=42)
#x_val, x_test, y_val, y_test = model_selection.train_test_split( x_val_test, y_val_test, test_size=0.333, random_state=42)
print('训练集个数',x_train.shape)
print(y_train)
#print(x_val_test.shape)
#print('验证集个数',x_val.shape[0])
print('测试集个数',x_test.shape)
#smo = SMOTE(random_state=42)
#x_train, y_train = smo.fit_resample(x_train, y_train)
y_train = y_train.reshape(y_train.shape[0],1)
print('训练集个数',x_train.shape)
##x_train = x_train.reshape(x_train.shape[0],1,x_train.shape[1])
#x_val = x_val.reshape(x_val.shape[0],1,x_val.shape[1])
#x_test = x_test.reshape(x_test.shape[0],1,x_test.shape[1])
i=1
results = []
skf= KFold(n_splits=10, shuffle=True, random_state=0)
for train_index, test_index in skf.split(x_train): 
    Y_train_label = y_train[train_index].astype('int')
    Y_val_label = y_train[test_index].astype('int')
    Y_train = np_utils.to_categorical(Y_train_label)
    Y_val = np_utils.to_categorical(Y_val_label)
    
    with mirrored_strategy.scope():
        # 建立MLP模型
        model = Sequential()
    # set the first hidden layer and set the input dimension
        model.add(Dense(input_dim=long,units=100,activation='relu'))
        model.add(Dense(units=200,activation='relu'))
        model.add(BatchNormalization())
        model.add(Dense(units=300,activation='relu'))
        model.add(BatchNormalization())
        model.add(Dense(units=100,activation='relu'))
        model.add(Dense(2,activation='sigmoid'))
        model.compile(loss='binary_crossentropy', optimizer='Adam',metrics=['accuracy'])

        # model.summary()
    tb_callback = tf.keras.callbacks.TensorBoard(log_dir="/home/stu1/xyx/sulf/sulf_dnn/logs/run{}".format(i), histogram_freq=1)
    history = model.fit(x_train[train_index], Y_train, epochs=100, batch_size=128, callbacks=[tb_callback])
    i += 1
    score = model.evaluate(x_train[test_index], Y_val, verbose=0)  
    print(score)
    Y_pro = model.predict(x_train[test_index])
    Y_pro = torch.Tensor(Y_pro)
    Y_pre = torch.argmax(Y_pro, 1)
    Y_pre = Y_pre.numpy()
    matrix = confusion_matrix(Y_val_label, Y_pre, labels=[1, 0])    # 混淆矩阵
    TP, FN, FP, TN = matrix[0][0], matrix[0][1], matrix[1][0], matrix[1][1]
    sensitivity = recall_score(Y_val_label, Y_pre, labels=[1, 0])   # 敏感性
    precision = precision_score(Y_val_label, Y_pre, labels=[1, 0])  # 精准性
    accuracy = accuracy_score(Y_val_label, Y_pre)
    specificity = TN / (TN + FP)    # 特异性 
    mcc = (TP * TN - FP * FN) / math.sqrt((TP + FN)*(TP+FP)*(TN+FP)*(TN+FN))   # 马氏相关系数
    fpr, tpr, _ = roc_curve(y_train[test_index].astype('int'), Y_pre)
    AUC = auc(fpr, tpr)
    results.append([sensitivity, specificity, precision, accuracy, mcc, AUC])

col = ['sensitivity', 'specificity', 'precision', 'accuracy', 'mcc', 'auc']
row = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10']
result = pd.DataFrame(results, columns=col, index=row)
print(result)
# savefile = '/home/stu1/audrey/malonylation/outputs/MLP.xlsx'
# result.to_excel(savefile)

    
    
